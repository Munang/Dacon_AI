{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import losses\n",
    "\n",
    "import numpy as np\n",
    "from keras import datasets  # mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:\\\\Users\\\\munan\\\\Desktop\\\\dacon\\\\dku_ai\\\\train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\munan\\\\Desktop\\\\dacon\\\\dku_ai\\\\test.csv\", index_col=0)\n",
    "submission = pd.read_csv(\"C:\\\\Users\\\\munan\\\\Desktop\\\\dacon\\\\dku_ai\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = 199991\n",
    "for col in train.columns[1:-1]:\n",
    "    train = train.loc[np.logical_and(train[col]>test[col].min(), train[col]<test[col].max())]\n",
    "    \n",
    "print('최종 행 개수 :', train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬럼 위치 변경 \n",
    "train2 = train[['class_train','redshift','nObserve','nDetect','u','g','r','i','z','dered_u','dered_g','dered_r','dered_i','dered_z','airmass_u','airmass_g','airmass_r','airmass_i','airmass_z'\n",
    "]]\n",
    "train = train[['class_train','redshift','nObserve','nDetect','u','g','r','i','z','dered_u','dered_g','dered_r','dered_i','dered_z','airmass_u','airmass_g','airmass_r','airmass_i','airmass_z'\n",
    "]]\n",
    "## 컬럼 위치 변경\n",
    "test2 =test[['redshift','nObserve','nDetect','u','g','r','i','z','dered_u','dered_g','dered_r','dered_i','dered_z','airmass_u','airmass_g','airmass_r','airmass_i','airmass_z'\n",
    "]]\n",
    "# 컬럼 위치 변경\n",
    "test = test[['redshift','nObserve','nDetect','u','g','r','i','z','dered_u','dered_g','dered_r','dered_i','dered_z','airmass_u','airmass_g','airmass_r','airmass_i','airmass_z'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수간 add, diff (per 5point)\n",
    "for i in range(1,6):\n",
    "    for j in range(4,19-i):\n",
    "        train2['diff'+str(i)+'_'+str(j)] = train2[train2.columns[j+i]] - train2[train2.columns[j]]\n",
    "        test2['diff'+str(i)+'_'+str(j)] = test2[test2.columns[j-1+i]] - test2[test2.columns[j-1]]\n",
    "        print('diff'+str(i)+'_'+str(j), ' : ', train2.columns[j+i], '-', train2.columns[j])\n",
    "        print('diff'+str(i)+'_'+str(j), ' : ', test2.columns[j-1+i], '-', test2.columns[j-1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    for j in range(4,19-i):\n",
    "        train2['add_'+str(i)+'_'+str(j)] = train2[train2.columns[j+i]] + train2[train2.columns[j]]\n",
    "        test2['add'+str(i)+'_'+str(j)] = test2[test2.columns[j-1+i]] + test2[test2.columns[j-1]]\n",
    "        print('add'+str(i)+'_'+str(j), ' : ', train2.columns[j+i], '-', train2.columns[j])\n",
    "        print('add'+str(i)+'_'+str(j), ' : ', test2.columns[j-1+i], '-', test2.columns[j-1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파장 변수 별 파장 차이 per 5 point\n",
    "diff_col = []\n",
    "for col in ['u','g','r','i','z']:\n",
    "    for i in range(3):\n",
    "        diff_col.append(col + '_' + str(i))\n",
    "mag_wave_diff_tr = pd.DataFrame(np.zeros((train2.shape[0], 15)), index=train2.index)\n",
    "mag_wave_diff_tt = pd.DataFrame(np.zeros((test2.shape[0], 15)))\n",
    "\n",
    "for i in range(0,15,5):\n",
    "    for j in range(5):\n",
    "        mag_wave_diff_tr.loc[:,j+i] = train2[train2.columns[4+j]] - train2[train2.columns[9+j+i]]\n",
    "        mag_wave_diff_tt.loc[:,j+i] = test2[test2.columns[3+j]] - test2[test2.columns[8+j+i]]\n",
    "        print(train.columns[4+j], ' - ',train2.columns[9+j+i], i+j)\n",
    "        print(test.columns[3+j], ' - ',test2.columns[8+j+i], i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수간 차이 \n",
    "diff_feature = []\n",
    "for c1, c2 in combinations(dered_col[::-1]+airmass_col[::-1]+z_col[::-1]+redshift_col[::-1],2):\n",
    "    new_c = f'{c1}_{c2}_diff'\n",
    "    train2[new_c] = train2[c1]-train2[c2]\n",
    "    test2[new_c] = test2[c1]-test2[c2]\n",
    "    diff_feature.append(new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수의 개수 정보 활용\n",
    "train2['t'] = 1\n",
    "test2['t'] = 0\n",
    "types = train2['class_train']\n",
    "all_df = pd.concat([train2.drop('class_train', axis=1), test2], axis=0)\n",
    "all_df['count_nDetect'] = all_df['nDetect'].map(all_df['nDetect'].value_counts())\n",
    "\n",
    "train2 = all_df[all_df['t']==1].drop('t', axis=1)\n",
    "test2 = all_df[all_df['t']==0].drop('t', axis=1)\n",
    "\n",
    "train2['class_train']= types.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['t'] = 1\n",
    "test2['t'] = 0\n",
    "types = train2['class_train']\n",
    "all_df = pd.concat([train2.drop('class_train', axis=1), test2], axis=0)\n",
    "all_df['count_nObserve'] = all_df['nObserve'].map(all_df['nObserve'].value_counts())\n",
    "\n",
    "train2 = all_df[all_df['t']==1].drop('t', axis=1)\n",
    "test2 = all_df[all_df['t']==0].drop('t', axis=1)\n",
    "\n",
    "train2['class_train']= types.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['t'] = 1\n",
    "test2['t'] = 0\n",
    "types = train2['class_train']\n",
    "all_df = pd.concat([train2.drop('class_train', axis=1), test2], axis=0)\n",
    "all_df['count_dered_u'] = all_df['dered_u'].map(all_df['dered_u'].value_counts())\n",
    "\n",
    "train2 = all_df[all_df['t']==1].drop('t', axis=1)\n",
    "test2 = all_df[all_df['t']==0].drop('t', axis=1)\n",
    "\n",
    "train2['class_train']= types.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['t'] = 1\n",
    "test2['t'] = 0\n",
    "types = train2['class_train']\n",
    "all_df = pd.concat([train2.drop('class_train', axis=1), test2], axis=0)\n",
    "all_df['count_dered_z'] = all_df['dered_z'].map(all_df['dered_z'].value_counts())\n",
    "\n",
    "train2 = all_df[all_df['t']==1].drop('t', axis=1)\n",
    "test2 = all_df[all_df['t']==0].drop('t', axis=1)\n",
    "\n",
    "train2['class_train']= types.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수간 max-max, min-min, sum-sum 설정을 위한 컬럼 리스트\n",
    "dered_col = [c for c in train.columns if c.find('dered')!=-1]\n",
    "airmass_col = [c for c in train.columns if c.find('airmass')!=-1]\n",
    "z_col = list(train.columns[4:9])\n",
    "redshift_col = [c for c in train.columns if c.find('redshift')!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix, g in zip(['dered','airmass','z_','redshift'], [dered_col,airmass_col,z_col,redshift_col]):\n",
    "    train2[f'{prefix}_max'] = train[g].max(axis=1)\n",
    "    test2[f'{prefix}_max'] = test[g].max(axis=1)\n",
    "    \n",
    "    train2[f'{prefix}_min'] = train[g].min(axis=1)\n",
    "    test2[f'{prefix}_min'] = test[g].min(axis=1)\n",
    "\n",
    "    train2[f'{prefix}_std'] = train[g].std(axis=1)\n",
    "    test2[f'{prefix}_std'] = test[g].std(axis=1)\n",
    "    \n",
    "    train2[f'{prefix}_sum'] = train[g].sum(axis=1)\n",
    "    test2[f'{prefix}_sum'] = test[g].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test,train 변수 중간 체크\n",
    "tmp = [x for x in train2.columns if x not in test2.columns]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수간 add, diff, div, mul combination \n",
    "a = train['class_train'].unique()\n",
    "b = ['u','g','i','z','redshift','dered_u','dered_g','dered_r','dered_i','dered_z','nObserve']\n",
    "\n",
    "train[\"nObserve\"] = train[\"nObserve\"].apply(np.log1p)\n",
    "test[\"nObserve\"] = test[\"nObserve\"].apply(np.log1p)\n",
    "\n",
    "for i , name in enumerate(b):\n",
    "    for i2 , name2 in enumerate(b):\n",
    "        if name==name2 :\n",
    "            pass\n",
    "        else :\n",
    "            train[str(name)+\"-\"+str(name2)] = train[name]-train[name2]\n",
    "            test[str(name)+\"-\"+str(name2)] = test[name]-test[name2]\n",
    "            \n",
    "for i , name in enumerate(b):\n",
    "    for i2 , name2 in enumerate(b):\n",
    "        if name==name2 :\n",
    "            pass\n",
    "        else :\n",
    "            train[str(name)+\"*\"+str(name2)+\"-\"+str(name2)] = train[name]*train[name2]-train[name2]\n",
    "            test[str(name)+\"*\"+str(name2)+\"-\"+str(name2)] = test[name]*test[name2]-test[name2]\n",
    "\n",
    "for i , name in enumerate(b):\n",
    "    for i2 , name2 in enumerate(b):\n",
    "        if name==name2 :\n",
    "            pass\n",
    "        else :\n",
    "            train[str(name)+\"/\"+str(name2)] = train[name]/train[name2]\n",
    "            test[str(name)+\"/\"+str(name2)] = test[name]/test[name2]\n",
    "\n",
    "for i , name in enumerate(b):\n",
    "    for i2 , name2 in enumerate(b):\n",
    "        if name==name2 :\n",
    "            pass\n",
    "        else :\n",
    "            train[str(name)+\"+\"+str(name2)] = train[name]+train[name2]\n",
    "            test[str(name)+\"+\"+str(name2)] = test[name]+test[name2]\n",
    "\n",
    "train['r+nObserve'] = train['r'] + train['nObserve']\n",
    "train['redshift+nObserve'] = train['redshift'] + train['nObserve']\n",
    "train['u*airmass_u'] = train['u'] * train['airmass_u']\n",
    "train['g*nDetect'] = train['g'] * train['nDetect']\n",
    "train['i*nDetect'] = train['i'] * train['nDetect']\n",
    "train['redshift*nDetect'] = train['redshift'] * train['nDetect']\n",
    "\n",
    "train['z-dered_u2'] = train['z'] - train['dered_u']\n",
    "train['z-dered_u3'] = train['z'] - train['dered_u']\n",
    "train['z-dered_u4'] = train['z'] - train['dered_u']\n",
    "train['z-dered_u5'] = train['z'] - train['dered_u']\n",
    "train['z-dered_u6'] = train['z'] - train['dered_u']\n",
    "train['z-dered_u7'] = train['z'] - train['dered_u']\n",
    "\n",
    "\n",
    "test['r+nObserve'] = test['r'] + test['nObserve']\n",
    "test['redshift+nObserve'] = test['redshift'] + test['nObserve']\n",
    "test['u*airmass_u'] = test['u'] * test['airmass_u']\n",
    "test['g*nDetect'] = test['g'] * test['nDetect']\n",
    "test['i*nDetect'] = test['i'] * test['nDetect']\n",
    "test['redshift*nDetect'] = test['redshift'] * test['nDetect']\n",
    "\n",
    "test['z-dered_u2'] = test['z'] - test['dered_u']\n",
    "test['z-dered_u3'] = test['z'] - test['dered_u']\n",
    "test['z-dered_u4'] = test['z'] - test['dered_u']\n",
    "test['z-dered_u5'] = test['z'] - test['dered_u']\n",
    "test['z-dered_u6'] = test['z'] - test['dered_u']\n",
    "test['z-dered_u7'] = test['z'] - test['dered_u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_ = pd.concat([train2 , train[train.columns[19:]]],axis =1)\n",
    "test2_ = pd.concat([test2, test[test.columns[18:]]],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝 BayesianOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_cv(learning_rate, n_estimators, num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    model = lgbm.LGBMClassifier(learning_rate=learning_rate,\n",
    "                                n_estimators=int(n_estimators),\n",
    "                                num_leaves = int(num_leaves),\n",
    "                                feature_fraction = feature_fraction,\n",
    "                                bagging_fraction = feature_fraction,\n",
    "                                max_depth = int(max_depth),\n",
    "                                lambda_l1 = lambda_l1,\n",
    "                                lambda_l2 = lambda_l2,\n",
    "                                min_split_gain = min_split_gain,\n",
    "                                min_child_weight = min_child_weight)\n",
    "    RMSE = cross_val_score(model, new_train_set_under_454, Y, scoring='accuracy', cv=5).mean()\n",
    "    return -RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'learning_rate' : (0.01, 0.3),\n",
    "           'n_estimators' : (50, 1000),\n",
    "           'num_leaves': (24, 45),\n",
    "           'feature_fraction': (0.1, 0.9),\n",
    "           'bagging_fraction': (0.8, 1),\n",
    "           'max_depth': (5, 50),\n",
    "           'lambda_l1': (0, 5),\n",
    "           'lambda_l2': (0, 3),\n",
    "           'min_split_gain': (0.001, 0.1),\n",
    "           'min_child_weight': (5, 50)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmBO = BayesianOptimization(f = lgbm_cv,pbounds = pbounds, verbose = 2, random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmBO.maximize(init_points=4, n_iter = 16, acq='ei', xi=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=lgbmBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_cv(max_depth,learning_rate, n_estimators, gamma,reg_alpha,reg_lambda,subsample,colsample_bytree, silent=True, nthread=-1):\n",
    "    model = xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                              learning_rate=learning_rate,\n",
    "                              n_estimators=int(n_estimators),\n",
    "                              silent=silent,\n",
    "                              nthread=nthread,\n",
    "                              gamma=gamma,\n",
    "                            reg_alpha = reg_alpha,\n",
    "                              reg_lambda = reg_lambda,\n",
    "                              subsample=subsample,\n",
    "                              colsample_bytree=colsample_bytree)\n",
    "    RMSE = cross_val_score(model, train2_set, y_train, scoring='accuracy', cv=5).mean()\n",
    "    return -RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 입력값의 탐색 대상 구간\n",
    "pbounds = {'max_depth': (5, 10),\n",
    "          'learning_rate': (0, 0.4),\n",
    "          'n_estimators': (50, 1000),\n",
    "          'gamma': (1., 0.01),\n",
    "          'reg_alpha': (0, 10),\n",
    "          'reg_lambda': (0, 10),\n",
    "          'subsample': (0.7, 0.8),\n",
    "          'colsample_bytree' :(0.5, 0.99)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboostBO = BayesianOptimization(f = XGB_cv,pbounds = pbounds, verbose = 2, random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복적으로 베이지안 최적화 수행\n",
    "# 시간을 줄이기 위해 N-n 값 10으로 지정\n",
    "# acq='ei'사용\n",
    "# xi=0.01 로 exploration의 강도를 조금 높임\n",
    "xgboostBO.maximize(init_points=2, n_iter = 10, acq='ei', xi=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = xgboostBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요도 기반 변수 재선정\n",
    "# 시간관계상 xgboost로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(train2_set, y_train, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = xgb.DMatrix(X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 중요도 기반 454개\n",
    "fscore = model.get_booster().get_fscore()\n",
    "n_list_all = list(fscore.keys())\n",
    "len(n_list_all)\n",
    "new_train_set_under_454 = train2_.loc[:,n_list_all]\n",
    "new_test_set_under_454 = test2_.loc[:,n_list_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 중요도 10이상인 249개\n",
    "x_under10_del = {key: value for key, value in fscore.items() if value>10}\n",
    "new_train_set_under_249 = train2_.loc[:,n_list]\n",
    "new_test_set_under_249 = test2_.loc[:,n_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요도 기반 454 변수 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_train_set_under_454, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dval = xgb.DMatrix(X_test,label=y_test)\n",
    "model = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요도 기반 249 변수 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_train_set_under_249, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dval = xgb.DMatrix(X_test,label=y_test)\n",
    "model = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요도 기반 454 변수 lgbm교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_columns)\n",
    "print(lgb_param_dart)\n",
    "x_train = new_train_set_under_454.copy()\n",
    "y_train = Y\n",
    "x_test = new_test_set_under_454.copy()\n",
    "\n",
    "num_class = 3\n",
    "oof_train = np.zeros((len(x_train),num_class))\n",
    "oof_test = np.zeros((len(x_test),num_class))\n",
    "log_loss_score_list= []   \n",
    "NFOLD = 5\n",
    "SEED = 42\n",
    "\n",
    "# stratifiedkfold 5 fold 사용\n",
    "folds = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=42)\n",
    "for fold_, (trn_index, val_index) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(f\"{fold_+1} FOLD Start!!\")\n",
    "    trn_x, trn_y = x_train.iloc[trn_index][train_columns], y_train.iloc[trn_index]\n",
    "    val_x, val_y = x_train.iloc[val_index][train_columns], y_train.iloc[val_index]\n",
    "    dtrain = lgbm.Dataset(trn_x, label=trn_y, silent=True)\n",
    "    dcross = lgbm.Dataset(val_x, label=val_y, silent=True)\n",
    "    \n",
    "    # dart는 얼리스탑핑이 안되서 한번 num_boost_round를 넉넉히 돌린다음에 5fold에서 가장 좋았던 round로 고정하고 돌린다.\n",
    "    clf = lgbm.train(lgb_param_dart, train_set=dtrain, num_boost_round=1000, valid_sets=[dtrain, dcross], \n",
    "                       verbose_eval=100)\n",
    "    \n",
    "    val_pred = clf.predict(val_x)\n",
    "    oof_train[val_index, :] = val_pred\n",
    "    \n",
    "    log_loss_score = log_loss(val_y, val_pred)\n",
    "    log_loss_score_list.append(log_loss_score)\n",
    "    print(f\"{fold_+1} FOLD LogLoss: \", log_loss_score)\n",
    "    \n",
    "    # 5fold 평균으로 제출\n",
    "    oof_test += clf.predict(x_test[train_columns])/NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseult_test =[]\n",
    "\n",
    "for i in oof_test:\n",
    "    reseult_test.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "submission = pd.DataFrame(data=reseult_test, index=sample_submission['id'])\n",
    "submission.to_csv('./submission_454_window.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요도 기반 249 변수 lgbm 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_columns)\n",
    "print(lgb_param_dart)\n",
    "x_train = new_train_set_under_249.copy()\n",
    "y_train = Y\n",
    "x_test = new_test_set_under_249.copy()\n",
    "\n",
    "num_class = 3\n",
    "oof_train = np.zeros((len(x_train),num_class))\n",
    "oof_test = np.zeros((len(x_test),num_class))\n",
    "log_loss_score_list= []   \n",
    "NFOLD = 5\n",
    "SEED = 42\n",
    "\n",
    "# stratifiedkfold 5 fold 사용\n",
    "folds = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=42)\n",
    "for fold_, (trn_index, val_index) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(f\"{fold_+1} FOLD Start!!\")\n",
    "    trn_x, trn_y = x_train.iloc[trn_index][train_columns], y_train.iloc[trn_index]\n",
    "    val_x, val_y = x_train.iloc[val_index][train_columns], y_train.iloc[val_index]\n",
    "    dtrain = lgbm.Dataset(trn_x, label=trn_y, silent=True)\n",
    "    dcross = lgbm.Dataset(val_x, label=val_y, silent=True)\n",
    "    \n",
    "    # dart는 얼리스탑핑이 안되서 한번 num_boost_round를 넉넉히 돌린다음에 5fold에서 가장 좋았던 round로 고정하고 돌린다.\n",
    "    clf = lgbm.train(lgb_param_dart, train_set=dtrain, num_boost_round=1000, valid_sets=[dtrain, dcross], \n",
    "                       verbose_eval=100)\n",
    "    \n",
    "    val_pred = clf.predict(val_x)\n",
    "    oof_train[val_index, :] = val_pred\n",
    "    \n",
    "    log_loss_score = log_loss(val_y, val_pred)\n",
    "    log_loss_score_list.append(log_loss_score)\n",
    "    print(f\"{fold_+1} FOLD LogLoss: \", log_loss_score)\n",
    "    \n",
    "    # 5fold 평균으로 제출\n",
    "    oof_test += clf.predict(x_test[train_columns])/NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseult_test =[]\n",
    "\n",
    "for i in oof_test:\n",
    "    reseult_test.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "submission = pd.DataFrame(data=reseult_test, index=sample_submission['id'])\n",
    "submission.to_csv('./submission_249_window.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
